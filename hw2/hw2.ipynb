{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage_section(soup, tag, attr_type, val): # 濾出需要的區塊\n",
    "    if attr_type == \"id\":\n",
    "        result = soup.find(tag, id=val)\n",
    "    elif attr_type == \"class\":\n",
    "        result = soup.find_all(tag, class_=val) # class 是保留字, bs4 用 class_\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_pages(menuUrl): # moviePages: 電影資訊的 List [ChineseName, EnglishName, Url]\n",
    "    moviePages = list()\n",
    "    while True:\n",
    "        r = requests.get(menuUrl)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        movieMenu = get_webpage_section(soup, \"div\", \"class\", \"release_movie_name\")\n",
    "        for movie in movieMenu:\n",
    "            # print(movie.select(\"a\"))\n",
    "            movieChiName = re.sub(r'\\s', '', movie.select(\"a\")[0].text)\n",
    "            movieEngName = re.sub(r'\\s', '', movie.select(\"a\")[1].text)\n",
    "            movieUrl = movie.select(\"a\")[0]['href']\n",
    "            moviePages.append([movieChiName, movieEngName, movieUrl])\n",
    "        ### 掃每一頁\n",
    "        nextPage = get_webpage_section(soup, \"li\", \"class\", \"nexttxt\")\n",
    "        if nextPage != [] and nextPage[0].find(\"a\") != None: # 若下一頁存在, 更新 menuUrl, loop 繼續抓\n",
    "            menuUrl = nextPage[0].find(\"a\")['href']\n",
    "            # print(menuUrl)\n",
    "        else:\n",
    "            break\n",
    "    return moviePages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_info(movieInfo): # movieInfo: [ChineseName, EnglishName, Url] # 濾出 分類, 上映時間, 劇情介紹\n",
    "    r = requests.get(movieInfo[2]) # movieInfo[2]: 電影資訊頁面的網址\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    # 分類\n",
    "    movieClassSec = get_webpage_section(soup, \"div\", \"class\", \"level_name_box\")\n",
    "    movieInfo.append([re.sub(r'\\s', '', movieCls.text) for movieCls in movieClassSec[0].select(\"a\")])\n",
    "    # 上映時間\n",
    "    moviePage = get_webpage_section(soup, \"div\", \"class\", \"movie_intro_info_r\")\n",
    "    movieInfo.append(moviePage[0].find(\"span\").text)\n",
    "    # 劇情介紹\n",
    "    movieStory = get_webpage_section(soup, \"span\", \"id\", \"story\")\n",
    "    movieInfo.append(re.sub(r'\\s', '', movieStory.text))\n",
    "    \n",
    "    # 演員 Url\n",
    "    movieActors = get_webpage_section(soup, \"ul\", \"class\", \"starlist\")\n",
    "    print(movieActors)\n",
    "    print(movieActors[0].find(\"a\"))\n",
    "    print(movieActors[0].find(\"a\")['href'])\n",
    "    input()\n",
    "    return movieInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_movie_info(movieList): # to json\n",
    "    movieInfoList = list()\n",
    "    for movie in movieList: # movie: [Name, Name, Url]\n",
    "        movieInfo = get_movie_info(movie) \n",
    "        movieInfoList.append(movieInfo[:2] + movieInfo[3:]) # 不需要 Url (movieInfo[2])\n",
    "    movieJson = dict()\n",
    "    for idx in range(len(movieInfoList)):\n",
    "        mov_dict = dict()\n",
    "        for jdx in range(len(movieInfoList[idx])):\n",
    "            if jdx == 0: mov_dict['Chinese Name'] = movieInfoList[idx][jdx]\n",
    "            elif jdx == 1: mov_dict['English Name'] = movieInfoList[idx][jdx]\n",
    "            elif jdx == 2: mov_dict['Movie Categories'] = movieInfoList[idx][jdx]\n",
    "            elif jdx == 3: mov_dict['Release Date'] = movieInfoList[idx][jdx][5:]\n",
    "            elif jdx == 4: mov_dict['Storyline Intro'] = movieInfoList[idx][jdx]\n",
    "        movieJson[ str(idx) ] = mov_dict\n",
    "    # print(movieJson)\n",
    "    return movieInfoList, movieJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://movies.yahoo.com.tw/movie_intheaters.html?page=2\n",
      "http://movies.yahoo.com.tw/movie_intheaters.html?page=3\n",
      "http://movies.yahoo.com.tw/movie_intheaters.html?page=4\n",
      "http://movies.yahoo.com.tw/movie_intheaters.html?page=5\n",
      "http://movies.yahoo.com.tw/movie_intheaters.html?page=6\n",
      "http://movies.yahoo.com.tw/movie_intheaters.html?page=7\n",
      "http://movies.yahoo.com.tw/movie_comingsoon.html?page=2\n",
      "http://movies.yahoo.com.tw/movie_comingsoon.html?page=3\n",
      "http://movies.yahoo.com.tw/movie_comingsoon.html?page=4\n",
      "http://movies.yahoo.com.tw/movie_comingsoon.html?page=5\n",
      "http://movies.yahoo.com.tw/movie_comingsoon.html?page=6\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file = open('movie_info.txt', 'w')\n",
    "    r = requests.get(\"https://movies.yahoo.com.tw/\")\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    sel = get_webpage_section(soup, \"ul\", \"id\", \"mainmenu\").select(\"a\")\n",
    "    mainmenu = dict()\n",
    "    # 爬下這三個 menu 的網址\n",
    "    for s in sel:\n",
    "        for t in ['本週新片', '上映中', '即將上映']: \n",
    "            if t in s.text: # 是以上這些種類的, 連結存放到 main menu\n",
    "                mainmenu[t] = s['href'] \n",
    "    movieList = list()\n",
    "    # 掃 menu 的電影, 爬下電影資訊的網址\n",
    "    for movie, url in mainmenu.items():\n",
    "        movieList += get_movie_pages(url)\n",
    "    # 從電影網址\n",
    "    movieInfoList, movieJson = pack_movie_info(movieList) # movieInfoList: Pure List, movieJson: Json for outfile\n",
    "    # print(movieInfoList)\n",
    "    \n",
    "    json.dump(movieJson, file, indent=4, ensure_ascii=False)\n",
    "    file.close()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"movie_info.txt\", \"r\")\n",
    "print(file.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "if li == []:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
