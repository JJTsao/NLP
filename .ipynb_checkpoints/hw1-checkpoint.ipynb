{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "import collections\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import log10\n",
    "\n",
    "jieba.set_dictionary('./dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(articles):\n",
    "    dataset = list()\n",
    "    for article in articles[:10]: # 先少一點\n",
    "        sentences = article[:-1].split('\\t') # sentences: list\n",
    "        for i in range(len(sentences)): # iterate 時不會直接改到原本容器, 所以要用 index traverse\n",
    "            sentences[i] = re.sub(r'\\W+', \"\", sentences[i])\n",
    "        parsed_sentences = list()\n",
    "        for sentence in sentences:\n",
    "            words = list(jieba.cut(sentence, cut_all=False)) # 一句一句切\n",
    "            parsed_sentences.append(words) # 切過的句子組合成文章\n",
    "        # print(parsed_sentences)\n",
    "        dataset.append(parsed_sentences) # 文章組合成檔案集 # parsed_sentences = article\n",
    "    # print(dataset)\n",
    "    return list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(t, article): # t: 詞\n",
    "    word_statistics_in_article = collections.Counter()\n",
    "    for sentence in article:\n",
    "        word_statistics_in_article += collections.Counter(sentence)\n",
    "    # print(word_statistics_in_article)\n",
    "    ### 計算 tf\n",
    "    total = sum(word_statistics_in_article.values(), 0.0)\n",
    "    word_tf_in_article = {key: round((val/total), 2) for key, val in word_statistics_in_article.items()}\n",
    "    # print(word_tf_in_article)\n",
    "    if t in word_tf_in_article: \n",
    "        return word_tf_in_article[t]\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(t, dataset):\n",
    "    occurrence = 0.0\n",
    "    for article in dataset:\n",
    "        for sentence in article:\n",
    "            if t in sentence:\n",
    "                occurrence += 1\n",
    "            else:\n",
    "                break\n",
    "    # print(len(dataset))\n",
    "    # print(occurrence)\n",
    "    return round(log10(len(dataset) / occurrence), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tf_in_dataset(dataset):\n",
    "    all_words_count = collections.Counter()\n",
    "    for article in dataset:\n",
    "        for sentence in article:\n",
    "            all_words_count += collections.Counter(sentence)\n",
    "    total = sum(all_words_count.values(), 0.0)\n",
    "    all_words_tf = {key: round((val/total), 3) for key, val in sorted(all_words_count.items(), key=lambda x: x[1], reverse=True)}\n",
    "    return all_words_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'為什麼': 0.026, '會': 0.026, '人': 0.026, '的': 0.026, '嗎': 0.019, '不': 0.019, '是': 0.019, '脫節': 0.019, '有': 0.019, '被': 0.013, '這群': 0.013, '不會': 0.013, '都': 0.013, '來': 0.013, '阿瑞': 0.013, '斯': 0.013, '了': 0.013, '最': 0.013, '系': 0.013, '看': 0.013, '棒球': 0.013, '肥宅': 0.013, '達摩': 0.013, '3D': 0.013, '小': 0.013, '人會畫': 0.013, '機車': 0.013, '聖': 0.006, '結石': 0.006, '酸': 0.006, '而': 0.006, '質感': 0.006, '劇本': 0.006, '成員': 0.006, '差': 0.006, '很多': 0.006, '好': 0.006, '不要': 0.006, '拿': 0.006, '腎結石': 0.006, '污辱': 0.006, '慶祝': 0.006, '228': 0.006, '罵': 0.006, '可是': 0.006, '慶': 0.006, '端午': 0.006, '因為': 0.006, '屈原': 0.006, '台灣人': 0.006, '楚': 0.006, '國人': 0.006, '有沒有': 0.006, '戰神': 0.006, '八卦': 0.006, '爵士': 0.006, '就是': 0.006, '男': 0.006, '主角': 0.006, '最後': 0.006, '死': 0.006, '理論': 0.006, '與': 0.006, '實務': 0.006, '哪個': 0.006, '你問': 0.006, '簡單': 0.006, '多': 0.006, 'PTT': 0.006, '這麼多': 0.006, '才': 0.006, '系壘': 0.006, '一堆': 0.006, '胖子': 0.006, '祖師': 0.006, '傳': 0.006, '那麼': 0.006, '好看': 0.006, '從頭到尾': 0.006, '被動': 0.006, '別人': 0.006, '問他': 0.006, '問題': 0.006, '畫家': 0.006, '當家': 0.006, '對': 0.006, '天龍人': 0.006, '說': 0.006, '宜蘭': 0.006, '4': 0.006, '南部': 0.006, '還': 0.006, '４': 0.006, '東部': 0.006, '他國': 0.006, '事務': 0.006, '推出': 0.006, 'uber': 0.006, '或': 0.006, '計程': 0.006, '怎樣': 0.006, '載到': 0.006, '很': 0.006, '痛苦': 0.006, '台中': 0.006, '龍邦': 0.006, '世貿': 0.006, '跳樓': 0.006, '曾經': 0.006, '當過': 0.006, '全台': 0.006, '第一': 0.006, '高樓': 0.006, '可惜': 0.006, '不到': 0.006, '一年': 0.006}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file = open(\"./hw1-dataset.txt\", mode='r')\n",
    "    articles = file.readlines()\n",
    "    dataset = preprocessing(articles)\n",
    "    \n",
    "    ### 統計高頻\n",
    "    # print(word_tf_in_dataset(dataset)) 高頻詞(已排序)\n",
    "    \n",
    "    ### 統計 tf-idf 高\n",
    "    \n",
    "#     for article in dataset:\n",
    "#         print(tf('為什麼', article))\n",
    "#     print(idf('為什麼', dataset))\n",
    "    \n",
    "    file.close()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['為什麼 聖結石 會被酸而 這群人 不會？\\t質感 劇本 成員 都差很多好嗎 不要拿腎結石來污辱這群人\\n', '為什麼慶祝228會被罵可是慶端午不會？\\t因為屈原不是台灣人，是楚國人。\\n', '有沒有戰神阿瑞斯的八卦?\\t爵士就是阿瑞斯 男主角最後死了\\n']\n"
     ]
    }
   ],
   "source": [
    "dataset = open(\"./hw1-dataset.txt\", mode='r')\n",
    "articles = list()\n",
    "for article in dataset: # article: 一行算一個文章\n",
    "    articles.append(article)\n",
    "    \n",
    "dataset.close()\n",
    "print(articles[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
